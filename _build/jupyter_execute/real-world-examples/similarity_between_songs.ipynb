{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79a1dda-da15-4719-aee2-8b4e7b047b06",
   "metadata": {},
   "source": [
    "# Similarity between Songs\n",
    "\n",
    "In this example, we use the official and other versions of _I'll Be There_ to illustrate similarity measurements between songs.\n",
    "\n",
    "## Using Audio Fingerprinting\n",
    "\n",
    "Assume that our database contains the official released _I'll Be There_ by Jess Glynne ([YouTube video](https://www.youtube.com/watch?v=iQp1_GfDhwQ)). Given a 10-second fragment as a query (clipped from 0:40 to 0:50 in the video and saved as `fragment-10s-from-official.wav`), our audio fingerprinting model can successfully recognise it along with the timestamp information. Following code block demonstrates the calculation using 1 CPU with 7.5 GB memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542fec63-2e89-47ab-9494-e22b147014cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Get inverted fingerprint hashes from database of 1 songs\n",
      "    using 59.432 seconds\n",
      "==> Get fingerprint hashes from queries of 1 fragments\n",
      "    using 0.657 seconds\n",
      "==> Query: ../../example-audio/i-will-be-there/fragment-10s-from-official.wav\n",
      "  - top1 match: official-by-jess-glynne\n",
      "  - top1's 00:39 match query's 00:00\n",
      "  - match till query's 9.195s (about 00:09)\n",
      "==> Index using 0.008 seconds\n"
     ]
    }
   ],
   "source": [
    "query_filenames = [\"fragment-10s-from-official.wav\"]\n",
    "query_filepaths = [\"../../example-audio/i-will-be-there/fragment-10s-from-official.wav\"]\n",
    "database_filenames = [\"official-by-jess-glynne.m4a\"]\n",
    "database_filepaths = [\"../../example-audio/i-will-be-there/official-by-jess-glynne.m4a\"]\n",
    "\n",
    "import sys, os, time\n",
    "sys.path.append(\"../../dv-audio-models/audio-fingerprint\")\n",
    "import fingerprint as fp\n",
    "\n",
    "def get_minsec(seconds):\n",
    "    m, s = divmod(int(seconds), 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    minsec = \"{:02d}:{:02d}\".format(m, s)\n",
    "    return minsec\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"==> Get inverted fingerprint hashes from database of {} songs\".format(len(database_filepaths)))\n",
    "db_songs = []\n",
    "for filename, filepath in zip(database_filenames, database_filepaths):\n",
    "    audio_input = [filename, filepath]\n",
    "    hashes = fp.fingerprint(audio_input)\n",
    "    invert = fp.get_invert_from_hashes(hashes)\n",
    "    db_songs.append(invert)\n",
    "\n",
    "database_hash_time = time.time()\n",
    "print(\"    using {} seconds\".format(round(database_hash_time - start_time, 3)))\n",
    "\n",
    "print(\"==> Get fingerprint hashes from queries of {} fragments\".format(len(query_filepaths)))\n",
    "query_songs_hashes = []\n",
    "for filename, filepath in zip(query_filenames, query_filepaths):\n",
    "    audio_input = [filename, filepath]\n",
    "    hashes = fp.fingerprint(audio_input)\n",
    "    query_songs_hashes.append(hashes)\n",
    "\n",
    "query_hash_time = time.time()\n",
    "print(\"    using {} seconds\".format(round(query_hash_time - database_hash_time, 3)))\n",
    "    \n",
    "query_matches = []\n",
    "for query_hashes in query_songs_hashes:\n",
    "    query_matches.append(fp.find_matches(query_hashes, db_songs))\n",
    "    \n",
    "for audio, match in zip(query_filepaths, query_matches):\n",
    "    print(\"==> Query: {}\".format(audio))\n",
    "    most_match = fp.find_most_match_seconds(match, 256/22050)\n",
    "    top1_match = most_match[\"top1_match\"]\n",
    "    top1_score = most_match[\"top1_score\"]\n",
    "    top1_starttime = most_match[\"top1_starttime\"]\n",
    "    query_matchstart = most_match[\"query_matchstart\"]\n",
    "    query_matchend = most_match[\"query_matchend\"]\n",
    "    query_matchdur = query_matchend - query_matchstart \n",
    "    if query_matchdur == 0 or top1_score < 10 * query_matchdur:\n",
    "        print(\"  - no match\")\n",
    "    else: \n",
    "        print(\"  - top1 match: {}\".format(top1_match))\n",
    "        print(\"  - top1's {} match query's {}\".format(get_minsec(top1_starttime), get_minsec(query_matchstart)))\n",
    "        print(\"  - match till query's {}s (about {})\".format(query_matchend, get_minsec(query_matchend)))\n",
    "\n",
    "index_time = time.time()\n",
    "print(\"==> Index using {} seconds\".format(round(index_time - query_hash_time, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e671138-da7e-4938-851e-8bfc05daecb2",
   "metadata": {},
   "source": [
    "## Using Version Identification\n",
    "\n",
    "Since audio fingerprinting is highly sensitive to identify a particular version of a piece of music, if any of the following versions are used as queries, no match will be returned, unless our database already contains fingerprints of these versions.\n",
    "- `violin-by-barbara-koba.m4a` ([Youtube video](https://www.youtube.com/watch?v=HZsNvx1bAzU)): original vocal parts are performed by violin;\n",
    "- `cover-by-kimberly-fransens.m4a` ([Youtube video](https://www.youtube.com/watch?v=VEQsJR7jK0c)): a cover song performed by another singer with guitar accompaniment.\n",
    "- `guitar-by-shoestringkaraoke.m4a` ([Youtube video](https://www.youtube.com/watch?v=e0c5V0gRxuI)): an instrumental version played by guitar.\n",
    "\n",
    "In this case, we can obtain the audio embeddings of the above 3 songs and then compare with our database, which contains the embedding of the official release (`official-by-jess-glynne.m4a`) and other 2023 songs randomly obtained from YouTube. If pairwise similarity measurement returns a distance score smaller than 0.45, the input query can be considered as a version candidate. Following code block demonstrates the calculation using 1 CPU with 7.5 GB memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f02f18-9e79-4377-a531-0f70df83f519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Step 1: audio pre-processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a5221efd9340fd8959857782872d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Step 2: obtain embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51698b7b851948f5a19555469cff6eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Step 3: embedding distance beetween 3 queries and official-by-jess-glynne.m4a\n",
      "  - violin-by-barbara-koba.m4a vs. official: 0.1826\n",
      "  - cover-by-kimberly-fransens.m4a vs. official: 0.1858\n",
      "  - guitar-by-shoestringkaraoke.m4a vs. official: 0.4458\n",
      "\n",
      "==> Step 4: similarity ranking\n",
      "  Measure the distance between 3 queries and database of\n",
      "  total 2024 songs in a pairwise fashion. If distance<0.45,\n",
      "  present rank | distance | filename of the database song.\n",
      "--> Query: violin-by-barbara-koba.m4a\n",
      "  - 1/2024 | 0.1826 | official-by-jess-glynne.m4a\n",
      "--> Query: cover-by-kimberly-fransens.m4a\n",
      "  - 1/2024 | 0.1858 | official-by-jess-glynne.m4a\n",
      "--> Query: guitar-by-shoestringkaraoke.m4a\n",
      "  * 1/2024 | 0.4182 | 0333_allday.mp3\n",
      "  - 2/2024 | 0.4458 | official-by-jess-glynne.m4a\n",
      "\n",
      "==> Calculation time (seconds) using 1 CPU with 7.5 GB memory\n",
      "  - Step 1 audio pre-processing: 44.007 \n",
      "  - Step 2 obtain embeddings: 40.868 \n",
      "  - Step 3 embedding distance: 0.001 \n",
      "  - Step 4 similarity ranking: 0.049 \n",
      "  - Total: 84.925\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../../dv-audio-models/audio-embedding\")\n",
    "import models\n",
    "from embedding import *\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# query info\n",
    "query_filenames = [\"violin-by-barbara-koba.m4a\", \n",
    "                   \"cover-by-kimberly-fransens.m4a\", \n",
    "                   \"guitar-by-shoestringkaraoke.m4a\"]\n",
    "query_list = [\"../../example-audio/i-will-be-there/violin-by-barbara-koba.m4a\", \n",
    "              \"../../example-audio/i-will-be-there/cover-by-kimberly-fransens.m4a\", \n",
    "              \"../../example-audio/i-will-be-there/guitar-by-shoestringkaraoke.m4a\"]\n",
    "# database info\n",
    "official_filenames = [\"official-by-jess-glynne.m4a\"]\n",
    "official_list = [\"../../example-audio/i-will-be-there/official-by-jess-glynne.m4a\"]\n",
    "embeddings_2023 = np.load(\"../../dv-audio-models/audio-embedding/demo_data/embeddings_2023.npy\")\n",
    "audiofile_2023 = np.load(\"../../dv-audio-models/audio-embedding/demo_data/audiofile_2023.npy\").tolist()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"==> Step 1: audio pre-processing\")\n",
    "audio_representation_list = []\n",
    "for audio_path in tqdm(query_list + official_list):\n",
    "    audio_representation = get_audio_representation(audio_path)\n",
    "    audio_representation_list.append(audio_representation)\n",
    "\n",
    "print()\n",
    "step1_time = time.time()\n",
    "    \n",
    "print(\"==> Step 2: obtain embeddings\")\n",
    "data = Dataset(audio_representation_list, out_length=None)\n",
    "dataloader = DataLoader(data, 1, shuffle=False, num_workers=0)\n",
    "model = load_model(models)\n",
    "embeddings = get_norm_embedding(model, dataloader)\n",
    "\n",
    "embedding_official = embeddings[-1]\n",
    "embeddings_query = embeddings[:len(query_list)]\n",
    "embeddings_database = np.vstack((embedding_official, embeddings_2023))\n",
    "\n",
    "print()\n",
    "step2_time = time.time()\n",
    "\n",
    "print(\"==> Step 3: embedding distance beetween {} queries and official-by-jess-glynne.m4a\".format(len(query_list)))\n",
    "for idx, embedding_query in enumerate(embeddings_query):\n",
    "    dis = 1 - np.matmul(embedding_query, embedding_official.T)\n",
    "    print(\"  - {} vs. official: {:.4f}\".format(query_filenames[idx], dis))\n",
    "\n",
    "print()    \n",
    "step3_time = time.time()\n",
    "\n",
    "print(\"==> Step 4: similarity ranking\")\n",
    "print(\"  Measure the distance between {} queries and database of\".format(len(query_list)))\n",
    "print(\"  total {} songs in a pairwise fashion. If distance<0.45,\".format(len(embeddings_database)))\n",
    "print(\"  present rank | distance | filename of the database song.\")\n",
    "\n",
    "audiofiles_database = official_filenames + audiofile_2023\n",
    "labels_database = [1] * len(official_filenames) + [0] * len(audiofile_2023)\n",
    "audio2label = dict()\n",
    "for audio, label in zip(audiofiles_database, labels_database):\n",
    "    audio2label[audio] = label\n",
    "\n",
    "for idx, embedding_query in enumerate(embeddings_query):\n",
    "    print(\"--> Query: {}\".format(query_filenames[idx]))\n",
    "    dis_list = 1 - np.matmul(embedding_query, embeddings_database.T)\n",
    "\n",
    "    row = []\n",
    "    for dis, audio in zip(dis_list, audiofiles_database):\n",
    "        row.append([dis, audio])\n",
    "    row.sort(key=lambda x: x[0])\n",
    "    n_database = len(row)\n",
    "    for i, (dis, audio) in enumerate(row):\n",
    "        label = audio2label[audio]\n",
    "        rank = i + 1\n",
    "        if label:\n",
    "            print(\"  - {}/{} | {:.4f} | {}\".format(rank, n_database, dis, audio))\n",
    "        else:\n",
    "            if dis < 0.45:\n",
    "                print(\"  * {}/{} | {:.4f} | {}\".format(rank, n_database, dis, audio))  \n",
    "\n",
    "print()\n",
    "step4_time = time.time()\n",
    "\n",
    "print(\"==> Calculation time (seconds) using 1 CPU with 7.5 GB memory\")\n",
    "print(\"  - Step 1 audio pre-processing: {:.3f} \".format(step1_time - start_time))\n",
    "print(\"  - Step 2 obtain embeddings: {:.3f} \".format(step2_time - step1_time))\n",
    "print(\"  - Step 3 embedding distance: {:.3f} \".format(step3_time - step2_time))\n",
    "print(\"  - Step 4 similarity ranking: {:.3f} \".format(step4_time - step3_time))\n",
    "print(\"  - Total: {:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d727c-23ea-4781-9919-2de0eb0f6687",
   "metadata": {},
   "source": [
    "We can observe from the results in Step 4 that using the current thresholding value may retrieve songs not related to the query. In real-world applications, the notion of similarity used to compare different audio recordings largely depends on the respective application as well as the user requirements. Therefore this thresholding value can be adjusted according to the application scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}