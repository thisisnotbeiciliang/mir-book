

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Music Identification &#8212; From Explicit to Implicit: Audio Embeddings for Music Content Services</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'audio-models/music_identification';</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Audio Embedding" href="audio_embedding.html" />
    <link rel="prev" title="Music Classification" href="music_classification.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    <p class="title logo__title">From Explicit to Implicit: Audio Embeddings for Music Content Services</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">AUDIO MODELS</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="representations.html">Representing Audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="music_classification.html">Music Classification</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Music Identification</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_embedding.html">Audio Embedding</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">REAL WORLD EXAMPLES</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../real-world-examples/content_based_recommendation.html">Content-based Recommendation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../real-world-examples/similarity_between_songs.html">Similarity between Songs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../real-world-examples/identification_in_podcasts.html">Identification in Podcasts</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">RESOURCES</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../resources/comparison.html">Technology Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refs.html">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/about_beici.html">About Beici</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/audio-models/music_identification.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Music Identification</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#peak-based-fingerprints">Peak-based Fingerprints</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embedding-based-fingerprints">Embedding-based Fingerprints</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beyond-fingerprints-for-version-identification">Beyond Fingerprints for Version Identification</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="music-identification">
<h1>Music Identification<a class="headerlink" href="#music-identification" title="Permalink to this headline">#</a></h1>
<p>Since 2000, there have been multiple services that help users identify the audio recording and deliver suitable content information. A typical scenario is that a user, also called the client, records a short audio fragment of the unknown song using a smartphone. The audio fragment is then converted into so-called <strong>audio fingerprints</strong>, which are compact and descriptive audio features. These fingerprints are transmitted to the identification service, also called the server. The server hosts various data resources including a fingerprint database that covers all music recordings to be identified, as well as a metadata database that contains content information linked to these recordings. The server receives the query fingerprints sent by the client and compares them with the fingerprints contained in the database. This step is typically realized by an efficient database look-up supported by suitable index structures. In the case of a successful identification, the server retrieves the content information linked to the identified fingerprints and sends back the desired metadata to the client. The following figure presents a schematic overview of the underlying client–server model <span id="id1">[<a class="reference internal" href="../refs.html#id7" title="Meinard Müller. Fundamentals of Music Processing – Audio, Analysis, Algorithms, Applications. Springer Verlag, 2015. ISBN 978-3-319-21944-8.">Muller15</a>]</span>.</p>
<figure class="align-center" id="am-af-flowchart">
<a class="reference internal image-reference" href="../_images/am-af-flowchart.png"><img alt="../_images/am-af-flowchart.png" src="../_images/am-af-flowchart.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 9 </span><span class="caption-text">Schematic overview of the client–server model of the described music identification service.</span><a class="headerlink" href="#am-af-flowchart" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>There are various ways to design and compute fingerprints. In real-world applications, these fingerprints need to fulfil certain requirements including high specificity (to distinguish an audio fragment from millions of others), robustness (against background noise and signal distortions), compactness (to be easily transmitted, stored, and indexed), and scalability (for millions of recordings).</p>
<section id="peak-based-fingerprints">
<h2>Peak-based Fingerprints<a class="headerlink" href="#peak-based-fingerprints" title="Permalink to this headline">#</a></h2>
<p>Audio fingerprint based on the concept of spectral peaks consists of a sparse set of characteristic points in the time–frequency plane. Such peaks often remain unchanged even in the presence of noise and additional sound sources. This peak-based fingerprint, which was introduced by Avery Wang <span id="id2">[<a class="reference internal" href="../refs.html#id8" title="Avery Wang. An industrial strength audio search algorithm. In Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 7–13. Baltimore, Maryland, USA, 2003.">Wan03</a>]</span>, is now successfully used in commercial audio identification systems.</p>
<figure class="align-center" id="am-af-constellation">
<a class="reference internal image-reference" href="../_images/am-af-constellation.png"><img alt="../_images/am-af-constellation.png" src="../_images/am-af-constellation.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">Illustration of the identification system using peak-based fingerprints.</span><a class="headerlink" href="#am-af-constellation" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#am-af-constellation"><span class="std std-numref">Fig. 10</span></a> illustrates the basic retrieval concept of the identification system using peak-based fingerprints. The extracted peaks are superimposed to the STFT spectrograms for an example database document (30 seconds of the recording) and a query fragment (10 seconds), as seen in (a) and (b), respectively. The peak-picking step reduces the complex spectrogram to a “constellation map”, a low-dimensional sparse representation of the original signal by means of a small set of time-frequency points, see (c) and (d). Finally, for the database look-up, the constellation map for a query fragment is locally compared to the one for all database fragments of the same size by counting peaks that occur in both constellation maps. This procedure is illustrated in (e) showing the superposition of the database fingerprints and time-shifted query fingerprints. Both constellation maps show a high consistency at a fragment of the database document starting at time position 10 seconds, which indicates a hit.</p>
<p>In the matching processes described above, the query needs to be compared against all sections of all documents contained in the database. Obviously, such an exhaustive search strategy is not feasible for large databases containing millions of recordings. To facilitate fast information access without sacrificing the accuracy of the retrieval results, indexing technique is typically used. It optimises speed and performance by cutting down the search space through suitable look-up operations. In our fingerprinting context, peak pairs are considered as hashes to construct index. Pairs are formed of the anchor and each peak in the target zone, and a hash value is obtained for each pair of peaks as a combination of both frequency values and the time difference between the peaks as indicated in <a class="reference internal" href="#am-af-hash"><span class="std std-numref">Fig. 11</span></a>. We do not further describe the indexing steps here. For details, we refer to Section 7.1.3 of <span id="id3">[<a class="reference internal" href="../refs.html#id7" title="Meinard Müller. Fundamentals of Music Processing – Audio, Analysis, Algorithms, Applications. Springer Verlag, 2015. ISBN 978-3-319-21944-8.">Muller15</a>]</span> and <span id="id4">[<a class="reference internal" href="../refs.html#id8" title="Avery Wang. An industrial strength audio search algorithm. In Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 7–13. Baltimore, Maryland, USA, 2003.">Wan03</a>]</span>.</p>
<figure class="align-center" id="am-af-hash">
<a class="reference internal image-reference" href="../_images/am-af-hash.png"><img alt="../_images/am-af-hash.png" src="../_images/am-af-hash.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">Illustration of the peak pairing strategy.</span><a class="headerlink" href="#am-af-hash" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="embedding-based-fingerprints">
<h2>Embedding-based Fingerprints<a class="headerlink" href="#embedding-based-fingerprints" title="Permalink to this headline">#</a></h2>
<p>Google proposed <em>Now Playing</em> <span id="id5">[<a class="reference internal" href="../refs.html#id20" title="Beat Gfeller, Ruiqi Guo, Kevin Kilgour, Sanjiv Kumar, James Lyon, Julian Odell, Marvin Ritter, Dominik Roblek, Matthew Sharifi, Mihajlo Velimirović, and others. Now playing: continuous low-power music recognition. arXiv preprint arXiv:1711.10958, 2017.">GGK+17</a>]</span>, a music recognizer using a pre-trained neural network which generates compact and discriminative fingerprints at a rate of one 96 dimensional embedding per second. Since each embedding is a fix-length vector, existing similarity search libraries can be used in the matching process. This improves both the computational speed of the audio fingerprints as well as reduce their size while maintaining the accuracy.</p>
</section>
<section id="beyond-fingerprints-for-version-identification">
<h2>Beyond Fingerprints for Version Identification<a class="headerlink" href="#beyond-fingerprints-for-version-identification" title="Permalink to this headline">#</a></h2>
<p>Although robust to many kinds of signal distortions, the discussed fingerprints are designed to be highly sensitive to a particular version of a piece of music. They are not designed for handling temporal or melodic deformations. This means if the query is another version, such as cover songs and instrumental recordings, audio fingerprinting will fail to identify the underlying music. Therefore, one needs other techniques to identify different versions of a given recording to protect copyrights of not only the actual sound recording, but also the musical composition.</p>
<p>Given a music recording of a musical piece, version identification aims at automatically retrieving all recorded versions (cover songs, instrumental, remixes, etc.) of the same piece from a music collection. Here, the query typically consists of an entire recording, as opposed to audio fingerprinting, where the query is only a small audio fragment. Therefore, version identification is usually considered <strong>a song-level retrieval task</strong>, where a single similarity measure is used to globally compare entire songs.</p>
<p>The basic assumption in version identification is that the original and a derivative version of a piece of music typically share some common characteristics. However, due to possible structural differences between these versions, it is not clear where these common elements occur. In view of the many possible kinds of modifications that may be applied when creating new versions, it is not realistic to assume that one can deal with all the resulting variations by using a single technique. <strong>We focus on the scenario where the versions to be identified share a similar melodic or harmonic progression.</strong> On the other side, we allow differences in aspects such as tempo, instrumentation, timbre, and the overall musical structure.</p>
<p>In our system, we can represent an audio recording as a neural network embedding, which is able to capture tonal elements of music recordings while showing a high degree of invariance with regard to a wide range of modifications. Given a music recording of arbitrary length as the input query, fixed-length embedding is obtained and used for similarity measurement as follows:</p>
<ul class="simple">
<li><p>First, the input audio recording is processed into a time-frequency representation <span class="math notranslate nohighlight">\(|X(t, f)|\)</span>.</p></li>
<li><p>Second, <span class="math notranslate nohighlight">\(|X(t, f)|\)</span> is fed into the trained neural network to obtain audio embedding, which is an array with fixed length <span class="math notranslate nohighlight">\(e \in \mathbb{R}^{L}\)</span>.</p></li>
<li><p>Third, a distance matrix (or similarity matrix) is computed by comparing <span class="math notranslate nohighlight">\(e \in \mathbb{R}^{L}\)</span> to the embedding database in a pairwise fashion. Here we use cosine distance for measurement.</p></li>
<li><p>Finally, given the distance scores between the query and every song in the database, candidates of versions are decided using a threshold. The smaller the distance, the greater the degree of similarity. Therefore any songs with a distance smaller than the threshold are considered as identified versions.</p></li>
</ul>
<p>Compared to alignment-based systems used in cover song identification tasks, such as <em>Qmax</em> proposed in <span id="id6">[<a class="reference internal" href="../refs.html#id9" title="Joan Serrà, Xavier Serra, and Ralph G Andrzejak. Cross recurrence quantification for cover song identification. New Journal of Physics, 11(9):093017, sep 2009.">SerraSA09</a>]</span>, embedding-based system can remarkably improve computation efficiency without sacrificing the accuracy, thus feasible for large databases. For example, this system can achieve a mean average precision (MAP) of 0.88 on the <a class="reference external" href="https://labrosa.ee.columbia.edu/projects/coversongs/covers80/"><em>cover80</em></a> dataset, and the runtime is at least 10 times faster than <em>Qmax</em>. For a more detailed investigation, we refer to <span id="id7">[<a class="reference internal" href="../refs.html#id10" title="Furkan Yesiler, Emilio Molina, Joan Serrà, and Emilia Gómez. Investigating the efficacy of music version retrieval systems for setlist identification. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 541–545. IEEE, 2021.">YMSerraGomez21</a>]</span>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./audio-models"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="music_classification.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Music Classification</p>
      </div>
    </a>
    <a class="right-next"
       href="audio_embedding.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Audio Embedding</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#peak-based-fingerprints">Peak-based Fingerprints</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embedding-based-fingerprints">Embedding-based Fingerprints</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beyond-fingerprints-for-version-identification">Beyond Fingerprints for Version Identification</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr. Beici Liang
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>